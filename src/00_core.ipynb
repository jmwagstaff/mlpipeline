{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run\n",
    "\n",
    "> API details.\n",
    "\n",
    "Features\n",
    "\n",
    "* each pipeline step is a function with defined outputs\n",
    "    * train, test, build_model, build_dataset\n",
    "* Use hydra and pydantic for config management\n",
    "* Add logging decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def foo(): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User defined pipeline functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user can define any number of functions which may or may not depend on the output of of functions. For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset() -> str: \n",
    "    print(\"calling get_dataset\")\n",
    "    return \"dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model() -> str: \n",
    "    print(\"calling get_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model() -> str: \n",
    "    print(\"calling get_model\")\n",
    "    return \"model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset: str, model: str) -> str: \n",
    "    print(f\"calling train with: {locals()}\")\n",
    "    return f\"{dataset=}, {model=}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(trained_model: str) -> int: \n",
    "    print(f\"calling test with {locals()}\")\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all of an empty list returns True, but we want it to return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_keys_in_dict(dictionary, keys):\n",
    "    in_dict = [k in dictionary.keys() for k in keys]\n",
    "    return all(in_dict) if in_dict else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(all_keys_in_dict({\"A\": 1, \"B\": 2},  [\"A\", \"B\"]), True) \n",
    "test_eq(all_keys_in_dict({\"A\": 1, \"B\": 2},  [\"A\"]), True) \n",
    "test_eq(all_keys_in_dict({\"A\": 1, \"B\": 2},  [\"A\", \"B\", \"C\"]), False) \n",
    "test_eq(all_keys_in_dict({\"A\": 1, \"B\": 2},  []), False)\n",
    "test_eq(all_keys_in_dict({},  [\"A\"]), False)\n",
    "test_eq(all_keys_in_dict({},  []), False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a dictionary where the keys are the function names, the values are dictionaries with the functions and parameters defined as such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = {\n",
    "    \"get_dataset\": {\"fn\": get_dataset, \"params\": []},\n",
    "    \"get_model\": {\"fn\": get_model, \"params\": []},\n",
    "    \"train\": {\"fn\": train, \"params\": [\"get_dataset\", \"get_model\"]},\n",
    "    \"test\": {\"fn\": test, \"params\": [\"train\"]},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fns(fns):\n",
    "    \n",
    "    # First run the independent functions\n",
    "    indep = {fn[\"fn\"].__name__: fn[\"fn\"]() for fn in fns.values() if not fn[\"params\"]}\n",
    "    for k in indep.keys():\n",
    "            del fns[k]\n",
    "            \n",
    "    # print(fns.keys())\n",
    "    \n",
    "    \n",
    "    while fns:\n",
    "        # print(fns)\n",
    "        next_level = {fn[\"fn\"].__name__: fn[\"fn\"](*[indep[x] for x in fn[\"params\"]]) for fn in fns.values() if all_keys_in_dict(indep, fn[\"params\"])}\n",
    "        indep.update(next_level)\n",
    "        # print(\"indep/n\", indep)\n",
    "        \n",
    "        # print(\"fns/n\", fns.keys())\n",
    "        \n",
    "        for k in set(indep.keys()).intersection(set(fns.keys())):\n",
    "            # print(k)\n",
    "            del fns[k]\n",
    "    \n",
    "    return indep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling get_dataset\n",
      "calling get_model\n",
      "calling train with: {'dataset': 'dataset', 'model': 'model'}\n",
      "calling test with {'trained_model': \"dataset='dataset', model='model'\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'get_dataset': 'dataset',\n",
       " 'get_model': 'model',\n",
       " 'train': \"dataset='dataset', model='model'\",\n",
       " 'test': 2}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_fns(fns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing a config yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to parse a config yaml a dictionary similar to the fns above. The yaml will have a section pipeline_steps as show below\n",
    "\n",
    "```\n",
    "pipeline_steps:\n",
    "    - get_dataset\n",
    "    - get_model\n",
    "    - train:get_dataset:get_model\n",
    "    - test:train\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yaml(filename):\n",
    "    with open(filename, 'r') as stream:\n",
    "        try:\n",
    "            parsed_yaml=yaml.safe_load(stream)\n",
    "            print(parsed_yaml)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "        \n",
    "    return parsed_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pipeline_steps': ['get_dataset', 'get_model', 'train:get_dataset:get_model', 'test:train']}\n"
     ]
    }
   ],
   "source": [
    "parsed_yaml = load_yaml(\"/home/IBEO.AS/jawa/projects/mlpipeline/src/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['get_dataset', 'get_model', 'train:get_dataset:get_model', 'test:train']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_yaml[\"pipeline_steps\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = {\n",
    "    \"get_dataset\": {\"fn\": get_dataset, \"params\": []},\n",
    "    \"get_model\": {\"fn\": get_model, \"params\": []},\n",
    "    \"train\": {\"fn\": train, \"params\": [\"get_dataset\", \"get_model\"]},\n",
    "    \"test\": {\"fn\": test, \"params\": [\"train\"]},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fn': 'get_model', 'params': []}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - carry on here\n",
    "\n",
    "s = parsed_yaml[\"pipeline_steps\"][1]\n",
    "sl = s.split(\":\")\n",
    "{\"fn\": sl[0], \"params\": sl[1:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
